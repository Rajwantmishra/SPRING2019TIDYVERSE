---
title: "TidyVerse"
author: "Rajwant Mishra"
date: "April 14, 2019"
 html_document:
    df_print: paged
    toc: true
    toc_float: true
    highlight: tango
    toc_depth: 2

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Load in the libraries that we'll need
library(tidyverse)
library(stringr)
library(lubridate)
library(cli)

 # html_document:
 #    df_print: paged
 #    toc: true
 #    toc_float: true
 #    highlight: tango
 #    toc_depth: 2

# output:
#   md_document:
#     variant: markdown_github

```
 


```{r}
All<- tidyverse::tidyverse_packages()

cli::boxx("Hello there! Let's Explore Tidyverse Package", padding = 1, float = "center")
print(All)
```


# Data Source 
from 
https://fivethirtyeight.com/features/the-worst-tweeter-in-politics-isnt-trump/

https://raw.githubusercontent.com/fivethirtyeight/data/master/twitter-ratio/BarackObama.csv

## readr : Read File {.tabset .tabset-fade .tabset-pills}
 There are many types of file and with readr package you can read your data directly in R using readr'r method.
 
>>
read_csv() and read_tsv() are special cases of the general read_delim(). They're useful for reading the most common types of flat file data, comma separated values and tab separated values, respectively. read_csv2() uses ; for the field separator and , for the decimal point. This is common in some European countries.


### Read_CSV
```{r echo=TRUE}

obama <- "https://raw.githubusercontent.com/fivethirtyeight/data/master/twitter-ratio/BarackObama.csv"

trump <- "https://github.com/fivethirtyeight/data/raw/master/twitter-ratio/realDonaldTrump.csv"

senators<- "https://github.com/fivethirtyeight/data/raw/master/twitter-ratio/senators.csv"


# Read in the dataset, we can user read_csv to read data from online or from local disk
D_obama <- read_csv(obama)
D_trump <- read_csv(trump)
D_senators <- read_csv(senators)


#I'll Work on only D_trump

# Let's take a look at what we have, We can use Glimse to see data with its data strcutre 
str(D_trump)
head(D_trump)
```

### Set Column Name

```{r}

#Lets add our Custom Column Name, there are many ways we can do it. 
# We can change the name after reading the data set. Or We can read data and apply our name as we read it.
# It looks like we need to skip five lines, which will remove the column names
# So lets create a vector with column names
names <- c("TweetDate", "Tweets", "TweetURL", "Count_Reply", "Count_Retweet", 
           "Count_Fav", "UserID")

# And then try reading the file again
Dn_trump <- read_csv(trump,skip=1, col_names = names)

head(Dn_trump)
```

### Read column by Type 

Lets say you want to force some column datatype before you read it, You can set type of column using `col_types` before you read in `read_csv`, i.e. c = character, i = integer, n = number, d = double, l = logical, f = factor, D = date, T = date time, t = time, ? = guess, or _/- to skip the column.

```{r}
# Lets Try altername 
names(D_trump) <- names

# Read in given Type of data
Type <- 'cccdddc'
read_csv(trump,col_types = Type )

#Chek data
head(D_trump)

```
### Subset
```{r}
# Lets say I want to Read Only 1st 2 Row of record
D_trump[1:2,]

```

```{r}
#Read 1st TWO colum of data
D_trump[,1:2]

```

```{r}

# Read 11 Row with 2nd and 3rd column only.
D_trump[11,2:3]
```

```{r}
#Create a subset of Data with Count_Fav greater thsn 100k (100000)

D_trump_Fav_100k <- filter(D_trump,D_trump$Count_Fav > 100000)

head(D_trump_Fav_100k)
```

## lubridate : Working with date

Want to read day, month, date, weekday, hours etc information from date time value. Lubridate gives handy function to do it:
### Read Date
```{r}
#Lets Work With Date
# Read 1 Record of date 
D_trump$TweetDate[1]

```


```{r}
#Lets Split Date and Time 
date_string <- str_split(D_trump$TweetDate[1]," ",n=2,simplify = TRUE)
date_string
data_date <- date_string[1,1]
data_date
data_time <- date_string[1,2]
data_time
new_date <- paste0(D_trump$TweetDate[1],":00")
new_date
lub_date <- mdy_hms(new_date)
lub_date
```

```{r}
# set Time Zone of the Date
tz(lub_date) <- "America/New_York"
```
### Month
```{r}
#TO get Month 
month(lub_date) # Will Return only Number 
month(lub_date,label = TRUE) # Will return Name of the month.
```
### Days
```{r}
day(lub_date) # Which Days in MOnth
days_in_month(lub_date) # How many months are in this Month

```
### Weekday
```{r}
# We can also extract some derived values such as the weekday
wday(lub_date)
wday(lub_date, label = TRUE)
```
### Day of the year
```{r}

# or day of the year
yday(lub_date)
```
### Change Timezone
```{r}
# Changes time
with_tz(lub_date)
with_tz(lub_date, "America/Chicago")
with_tz(lub_date, "America/Los_Angeles")
```
### Current Time  
```{r}
now()
tz(now())
```
### Date in Interval

 %within%
 
 Tests Whether A Date Or Interval Falls Within An Interval
 recycled according to standard R rules. If b is a list of intervals, a is checked if it falls within any of the      intervals in b. If a is an interval, both its start and end dates must fall within b to return TRUE.

```{r}
## recycling
dates <- ymd(c("2014-12-20", "2014-12-30", "2015-01-01", "2015-01-03"))
blackouts<- c(interval(ymd("2014-12-30"), ymd("2014-12-31")),
              interval(ymd("2014-12-30"), ymd("2015-01-03")))
dates %within% blackouts
```

```{r}
# lets Put all the date vlaues together 
D_trump$newDate <- mdy_hms(paste0(D_trump$TweetDate,":00"))
  tz(D_trump$newDate)<- "America/New_York"
 D_trump$month <- month(D_trump$newDate ,label = TRUE)
 D_trump$wday <- wday(D_trump$newDate, label = TRUE)

```
 
## ggplot2 package 
 
### Subset of Data 
```{r}

# create a subset of data with only valid data value 
 newTestDate <- D_trump[,c("newDate","month","wday","Count_Retweet","Count_Reply")]
```

### Bar graph
```{r}
# create the Base ggplot2 code to initialize it
g_base <- ggplot(newTestDate,mapping = aes(x=wday , y= Count_Reply, fill=wday))
g_base + geom_col()
```

### Using scatterplot 
```{r}

ggplot(newTestDate,mapping = aes(x=newDate , y= Count_Reply, color=wday)) + geom_point()

```


### Using facet_wrap
Using wrap function 
```{r}
# Use the code.
g_base + geom_col() + facet_wrap(~month(D_trump$newDate)) 

```

### Using Theme 
```{r}
  ggplot(newTestDate)+
  geom_density(mapping=aes(x=Count_Reply ),alpha=.2, fill="#FF6666")+facet_wrap(~month(newTestDate$newDate)) +
    ggtitle("Reply by Month") +
  ylab("Count Reply") + xlab("Month") +
   theme(legend.position="top")
  
 ggplot( fct_count(newTestDate$month),mapping = aes(x= f, y=n )) + geom_col() 
```

### Using Density 
```{r}   
 
  ggplot( fct_count(newTestDate$month))+
   geom_density(mapping=aes(x=n ),alpha=.2, fill="#FF6666") 
```

### Using Geom Smooth 
```{r}  
  
  filter(newTestDate,wday == "Sun") %>%
  ggplot(mapping = aes(x=date(newDate) , y=Count_Retweet , color=wday)) + 
    geom_smooth(alpha=.2,span=.5, method = 'auto',  stat = "smooth") 
```

 * Using smooth with method
 
```{r} 
   filter(newTestDate,wday %in% c("Sat","Sun","Mon","Tue")) %>%
  ggplot(mapping = aes(x=date(newDate) , y=Count_Retweet , color=wday)) +
  geom_smooth(method = lm, se = FALSE)
    
    
```


## dplyr : Working with Group by {.tabset .tabset-fade .tabset-pills}

### Checking Group By
  
```{r}
  
    
  
  
  
  print(newTestDate)
  
  # I want to list all Tweets by Month and day
  # We can user group_by to group our data. 
  # Note: Group_by has no impact on data untill we use with some other function to run aggregation on it. Like summarise 
  group_by(newTestDate,month,wday)%>%summarise(Tweetcount  = n()) 

```

```{r}
    
  #Lets validate your result with table 
    table(newTestDate$month,newTestDate$wday)
  
    group_by(newTestDate,month,wday)%>%summarise(Tweetcount  = sum(Count_Retweet))
    ungroup(newTestDate)
```

```{r}    
    # Lets take a long route to get the same data for our validation.
    # I'll Create a subset of data for MOnth = Jan and Weekday = Sun and then will do sum of count_retweet. 
    checkWeekDay <- filter(newTestDate,newTestDate$month=="Jan" & newTestDate$wday =="Sun")
    sum(checkWeekDay$Count_Retweet)
    # Wow, our data from last group_by output matches.


```


### Working with filter

```{r}

#---------------------------------

# filter()
# 

# List all the Tweet whcih has more than 100 reply 
filter(D_trump,D_trump$Count_Reply > 100)
```

## stringr package {.tabset .tabset-fade .tabset-pills}

### Find word

Find word starting with something 

```{r}
# Using Stringr lets say I want to know all the Tweets that were Retweeted. 
filter(D_trump,str_detect(D_trump$Tweets,"^RT")) 
```

### Find exact 

```{r}
# Check how many Time Border is as an issue got mention in tweet. 
filter(D_trump,str_detect(D_trump$Tweets," border|Border|BORDER")) 
```

### find all the Pattern 

```{r}
# We can use Filter to create SUBSET of data based on need
filter(D_trump,str_detect(D_trump$Tweets,"@[[:alnum:]]+")) 
```

```{r}
# We can also work on data column and store result for further processing 
At_Tweet<- str_extract_all(D_trump$Tweets,"@[[:alnum:]]+",simplify = TRUE)

tail(At_Tweet,15)

```


## dplyr : Working with Join {.tabset .tabset-fade .tabset-pills}
  + full_join
  + inner_join
  + anti_join
  + left_join
  + right_join
  + nest_join
  + semi_join

### Data

```{r}

#----------------------JOIN
table1 <- D_trump[5:20,c("TweetURL","TweetDate")]
table2 <- D_trump[1:15,c("TweetURL","Tweets")]

glimpse(table1)
glimpse(table2)
```

### Full_join

```{r}
# URL in Unique for each Tweet
table_Full <- table1 %>% dplyr::full_join(table2, by =c("TweetURL" = "TweetURL"))
glimpse(table_Full)
```

```{r}
# Note how all the Data set got clubbed here , we can see NA for Text for some Entry and NA for Created_at for some entry
table_Full
```

### inner_join

```{r}
#Inner Join 
table_Inner <- inner_join(table1,table2, by =c("TweetURL" = "TweetURL"))
```

```{r}
# Here table_Inner would have all the data that is common in table1 and Table2
table_Inner
```

### anti_join

```{r}
# if you want to list all the data from Table1, which is not in table2 we can use anti_join 
table_Anti <- dplyr::anti_join(table1,table2, by =c("TweetURL" = "TweetURL"))

table_Anti
```

### left_join

```{r}
# if you want to list all the data from Table1 i.e. Left table from below parameter and also wants to list all the matching data from right table i.e. table2, we can use left join
table_Left <- dplyr::left_join(table1,table2, by =c("TweetURL" = "TweetURL"))

table_Left
table1
```

### right_join

```{r}
# if you want to list all the data from Table2 i.e. RIGHT table from below parameter and also wants to list all the matching data from left table i.e. table1, we can use right_join
table_Right <- dplyr::right_join(table1,table2, by =c("TweetURL" = "TweetURL"))

table_Right
table2
```

### nest_join

```{r}
# Want to join table as nested tible use next_join 
table_Next <- dplyr::nest_join(table1,table2, by =c("TweetURL" = "TweetURL"))
table_Next
# Joined table2 is added a tible . 
table_Next[1,]
table_Next$url[1]
table_Next$table2[[1]]
```

```{r}
# We can use Keep to keep the column name 
table_NextKeep <- dplyr::nest_join(table1,table2, by =c("TweetURL" = "TweetURL"),keep= TRUE)
table_NextKeep[1,]
table_NextKeep$url[1]
table_NextKeep$table2[[1]]
```

### semi_join

```{r}
#return all rows from x (let table i.e. Table 1) where there are matching values in y (right table ie.e table 2) , keeping just columns from table1.
table_Semi <- dplyr::semi_join(table1,table2, by =c("TweetURL" = "TweetURL"))
table_Semi

```

## forcats package
```{r}
#---------------------------------

# The forcats package
# forcats is a core package in the tidyverse. It is installed via install.packages("tidyverse") and attached via  library(tidyverse). You can always load it individually via library(forcats). Main functions start with  fct_. There really is no coherent family of base functions that forcats replaces - that's why it's such a welcome addition.


data("diamonds")

str(diamonds$cut)

```

```{r}

# Same output with dplyr packge 

diamonds %>% 
  count(cut)

# Same output with forcats packge 

fct_count(diamonds$cut)

```

## CLI package :  

`r rule(center = " * CLI Package * ", line_col = "red") `

```{r}
rule(center = " * CLI Package * ", line_col = "red")
rule(line = "bar2")
rule(line = "dots2")
rule(center = " * RESULTS * ", col = "red")
list_spinners()
cli::boxx("Hello there!", padding = 1, float = "center")
```

